{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR1_Query.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o74yHRthVklo",
        "outputId": "e245ba06-b999-4d71-f6b9-e91722d442a3"
      },
      "source": [
        "import codecs\r\n",
        "import json \r\n",
        "import string\r\n",
        "import os\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "import ast \r\n",
        "import pandas as pd\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D-A9xTj2wMc"
      },
      "source": [
        "f = open('/content/drive/MyDrive/IRE/postinglist.json')             #loading posting list\r\n",
        "postings = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHBuMbZi7APe"
      },
      "source": [
        "f1 = open('/content/drive/MyDrive/IRE/invertedIndexing.json')              #loading the inverted indexing\r\n",
        "inverted_indexing = json.load(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJfVs5Q3cLWM"
      },
      "source": [
        "f2 = open('/content/drive/MyDrive/IRE/title_indexing.json')                         #loading title indexing\r\n",
        "title_indexing = json.load(f2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQRFIMhwUXzX"
      },
      "source": [
        "def preprocessing(texts):                                      #preprocessing function\r\n",
        "    #word_tokenize\r\n",
        "#     print(texts)\r\n",
        "#     print()\r\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\",  # Search for all non-letters\r\n",
        "                          \" \",          # Replace all non-letters with spaces\r\n",
        "                          texts)\r\n",
        "#     print(letters_only)\r\n",
        "#     print()\r\n",
        "    word_tokens = word_tokenize(letters_only)\r\n",
        "#     print(word_tokens)\r\n",
        "#     print()\r\n",
        "    #Lemmatization\r\n",
        "    lemmatizer = WordNetLemmatizer()\r\n",
        "    word_lemm = [lemmatizer.lemmatize(word) for word in word_tokens if word not in stopwords.words('english')]\r\n",
        "#     print(word_lemm)\r\n",
        "#     print()\r\n",
        "    return word_lemm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vkx7PK7c9pT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzLUpaJsF-J",
        "outputId": "0f7d2c07-cdb9-4f10-e62a-9ca18e44ea2f"
      },
      "source": [
        "title = title_indexing.keys()                 #showing how many documents are present\r\n",
        "title = list(title)\r\n",
        "len(title)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cuAEDA6am7L"
      },
      "source": [
        "def OR_merge(val,val1):                         #Merge or function for OR operation.\r\n",
        "  i,j =0,0 \r\n",
        "  compare = 0\r\n",
        "  doc = []\r\n",
        "  while i<len(val) and j<len(val1):\r\n",
        "    \r\n",
        "    compare = compare + 1\r\n",
        "    if val[i] == val1[j]:\r\n",
        "      doc.append(val[i])\r\n",
        "    else:\r\n",
        "      doc.append(val[i])\r\n",
        "      doc.append(val[j])\r\n",
        "    i = i+1\r\n",
        "    j = j+1   \r\n",
        "  if i<len(val):\r\n",
        "    for x in range(i,len(val)):\r\n",
        "      doc.append(val[x])\r\n",
        "  elif j<len(val1):\r\n",
        "    for x in range(j,len(val1)):\r\n",
        "      doc.append(val1[x])\r\n",
        "\r\n",
        "  return compare,doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cK7tceysRM7"
      },
      "source": [
        "def AND_merge(val,val1):                      #merge and function\r\n",
        "  i,j = 0,0 \r\n",
        "  compare = 0\r\n",
        "  doc =[]\r\n",
        "  while i < len(val) and j < len(val1):\r\n",
        "    compare = compare + 1\r\n",
        "    if val[i] == val1[j]:\r\n",
        "      doc.append(val[i])\r\n",
        "      i = i+1\r\n",
        "      j = j+1\r\n",
        "    elif val[i] < val1[j]:\r\n",
        "      i = i + 1\r\n",
        "    elif val[i] > val1[j]:\r\n",
        "      j = j+1    \r\n",
        "\r\n",
        "  return compare,doc    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gysrmFY1Yom"
      },
      "source": [
        "def AND_NOT(val,val1):                      #merge and function\r\n",
        "  i,j = 0,0 \r\n",
        "  compare = 0\r\n",
        "  doc =[]\r\n",
        "  while i < len(val) and j < len(val1):\r\n",
        "    compare = compare + 1\r\n",
        "    if val[i] == val1[j]:\r\n",
        "      i = i+1\r\n",
        "      j = j+1\r\n",
        "    elif val[i] < val1[j]:\r\n",
        "      doc.append(val[i])\r\n",
        "      i = i + 1\r\n",
        "    elif val[i] > val1[j]:\r\n",
        "      j = j+1    \r\n",
        "\r\n",
        "  return compare,doc    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIRAD-pO2Fdv"
      },
      "source": [
        "def OR_NOT(val,val1):\r\n",
        "  i,j = 0,0 \r\n",
        "  compare = 0\r\n",
        "  doc =[]\r\n",
        "  while i < len(val) and j < len(val1):\r\n",
        "    compare = compare + 1\r\n",
        "    if val[i] == val1[j]:\r\n",
        "      doc.append(val[i])\r\n",
        "      i = i+1\r\n",
        "      j = j+1\r\n",
        "    elif val[i] < val1[j]:\r\n",
        "      doc.append(val[i])\r\n",
        "      i = i + 1\r\n",
        "    elif val[i] > val1[j]:\r\n",
        "      j = j+1    \r\n",
        "\r\n",
        "  return compare,doc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsLYI-9L3W8c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEi-2TAxe_EC",
        "outputId": "f42d2a75-c557-4b4e-e6a6-707bb4e5c2fa"
      },
      "source": [
        "input1 = input(\"Enter the Query\")                 # input query\r\n",
        "print(\"Input Query is :\",input1)\r\n",
        "query = preprocessing(input1.lower())          #preprocessing\r\n",
        "print(\"Tokens are:\",query)                      #getting tokens after preprocessing\r\n",
        "i = 0\r\n",
        "j = 0\r\n",
        "res = []\r\n",
        "compare1 = 0\r\n",
        "while i < len(query):         \r\n",
        "  print(\"Enter 1 for OR operation\")\r\n",
        "  print(\"Enter 1 for And operation\")\r\n",
        "  print(\"Enter 3 for OR NOT operation\")\r\n",
        "  print(\"Enter 4 for And NOT operation\")\r\n",
        "  choice = input(\"Enter the desired Operation\")\r\n",
        "  choice = int(choice)\r\n",
        "  \r\n",
        "  if j == 0:\r\n",
        "    j = 1\r\n",
        "    i = i+2\r\n",
        "    term1 = query[0]\r\n",
        "    term2 = query[1]\r\n",
        "    print(term1)\r\n",
        "    \r\n",
        "    \r\n",
        "    k = inverted_indexing[term1]\r\n",
        "    k = str(k)\r\n",
        "    \r\n",
        "    val = postings[k].keys()\r\n",
        "    val = list(val)\r\n",
        "\r\n",
        "    k1 = inverted_indexing[term2]\r\n",
        "    k1 = str(k1)\r\n",
        "    val1 = postings[k1].keys()\r\n",
        "    val1 = list(val1)\r\n",
        "    print(\"val size\",len(val))\r\n",
        "    print(\"val1 size\",len(val1))\r\n",
        "\r\n",
        "\r\n",
        "    #print(\"true\")\r\n",
        "    if choice == 1:                 #for OR operation\r\n",
        "       #print(\"true\")\r\n",
        "       \r\n",
        "       \r\n",
        "       final_res = list(set(val1).union(set(val)))\r\n",
        "       #res.append(final_res)\r\n",
        "       print(\"result length\",len(final_res))\r\n",
        "       compare,doc = OR_merge(val,val1)\r\n",
        "       compare1 = compare1 + compare\r\n",
        "\r\n",
        "    if choice == 2:             #for AND operation\r\n",
        "       #print(\"true\")\r\n",
        "       if len(val) >= len(val1):\r\n",
        "         final_res = list(set(val1).intersection(set(val)))\r\n",
        "\r\n",
        "       else:\r\n",
        "           final_res = list(set(val).intersection(set(val1)))\r\n",
        "\r\n",
        "       compare,doc = AND_merge(val,val1)\r\n",
        "       compare1= compare + compare1    \r\n",
        "       \r\n",
        "       print(\"result length\",len(final_res))   \r\n",
        "\r\n",
        "    if choice == 3:                   #for OR NOT operation\r\n",
        "      without_val1 = set(title).difference(set(val1))\r\n",
        "      final_res = list(set(val).union(set(without_val1)))\r\n",
        "      compare,doc = OR_NOT(val,val1)\r\n",
        "      compare1= compare + compare1    \r\n",
        "      print(\"result length\",len(final_res))\r\n",
        "\r\n",
        "    if choice == 4:                #for AND NOT operation\r\n",
        "      without_val1 = set(title).difference(set(val1))\r\n",
        "      if len(without_val1) > len(val):\r\n",
        "          final_res = list(set(val).intersection(set(without_val1)))\r\n",
        "\r\n",
        "\r\n",
        "      else :\r\n",
        "         final_res = list(set(without_val1).intersection(set(val)))\r\n",
        "\r\n",
        "      compare,doc = AND_NOT(val,val1)\r\n",
        "      compare1= compare + compare1       \r\n",
        "\r\n",
        "\r\n",
        "      print(\"result length\",len(final_res))  \r\n",
        "\r\n",
        "  else:       #query for other than first two tokens\r\n",
        "    \r\n",
        "    j = 1\r\n",
        "    term = query[i]\r\n",
        "    k = inverted_indexing[term]\r\n",
        "    k = str(k)\r\n",
        "    val = postings[k].keys()\r\n",
        "    val = list(val)\r\n",
        "    print(\"val size\",len(val))\r\n",
        "    print(\"final_size size\",len(final_res))\r\n",
        "    if choice == 1:\r\n",
        "       \r\n",
        "       final_res = list(set(final_res).union(set(val)))\r\n",
        "       print(\"result length\",len(final_res))\r\n",
        "       compare,doc =  OR_merge(doc,val)\r\n",
        "       compare1 = compare + compare1\r\n",
        "\r\n",
        "\r\n",
        "    if choice == 2:\r\n",
        "       #print(\"true\")\r\n",
        "       if len(val) >= len(final_res):\r\n",
        "         final_res = list(set(final_res).intersection(set(val)))\r\n",
        "\r\n",
        "       else:\r\n",
        "           final_res = list(set(val).intersection(set(final_res)))\r\n",
        "\r\n",
        "       compare,doc = AND_merge(doc,val)\r\n",
        "       compare1 = compare + compare1     \r\n",
        "       \r\n",
        "       print(\"result length\",len(final_res))   \r\n",
        "\r\n",
        "    if choice == 3:\r\n",
        "         without_val = set(title).difference(set(val))\r\n",
        "         final_res = list(set(final_res).union(set(without_val)))\r\n",
        "         print(\"result length\",len(final_res))\r\n",
        "         compare,doc = OR_NOT(val,val1)\r\n",
        "         compare1= compare + compare1    \r\n",
        "\r\n",
        "    if choice == 4:\r\n",
        "      without_val = set(title).difference(set(val))\r\n",
        "      if len(without_val) > len(val):\r\n",
        "         final_res = list(set(final_res).intersection(set(without_val)))\r\n",
        "\r\n",
        "      else:\r\n",
        "        final_res = list(set(without_val).intersection(set(final_res)))\r\n",
        "\r\n",
        "      compare,doc = AND_NOT(val,val1)\r\n",
        "      compare1= compare + compare1      \r\n",
        "\r\n",
        "      print(\"result length\",len(final_res))  \r\n",
        "\r\n",
        "    i = i+1   \r\n",
        "\r\n",
        "print(\"lenth of result\",len(final_res))\r\n",
        "print(final_res)\r\n",
        "print(\"no of comparisions\",compare1)\r\n",
        "#print(\"lenth of doc\",len(doc))\r\n",
        "\r\n",
        "         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the Querytelephone paved roads.\n",
            "Input Query is : telephone paved roads.\n",
            "Tokens are: ['telephone', 'paved', 'road']\n",
            "Enter 1 for OR operation\n",
            "Enter 1 for And operation\n",
            "Enter 3 for OR NOT operation\n",
            "Enter 4 for And NOT operation\n",
            "Enter the desired Operation3\n",
            "telephone\n",
            "val size 36\n",
            "val1 size 8\n",
            "result length 463\n",
            "Enter 1 for OR operation\n",
            "Enter 1 for And operation\n",
            "Enter 3 for OR NOT operation\n",
            "Enter 4 for And NOT operation\n",
            "Enter the desired Operation4\n",
            "val size 121\n",
            "final_size size 463\n",
            "result length 345\n",
            "lenth of result 345\n",
            "['sre09.txt', 'gold3ber.txt', 'wanderer.fun', 'jackbstl.txt', 'lrrhood.txt', 'bulnland.txt', 'greatlrn.leg', 'grav', 'blasters.fic', 'horsdonk.txt', 'gemdra.txt', 'contrad1.hum', 'ltp', 'hotline1.txt', 'mindwar', 'quarter.c2', 'quarter.c11', 'blossom.pom', 'sre07.txt', 'buldream.txt', 'cow.exploder', 'bishop00.txt', 'mario.txt', 'idi.hum', 'elveshoe.txt', 'hole2nar.txt', 'lure.txt', 'ghost', 'sre02.txt', 'poem-1.txt', 'bulolli1.txt', 'blackrdr', 'korea.s', 'weeprncs.txt', 'corcor.hum', 'helmfuse.txt', 'spam.key', 'prince.art', 'sre08.txt', 'luf', 'peace.fun', 'alissadl.txt', 'kneeslapper.txt', 'fea3', 'sre05.txt', 's&m_plot', 'dakota.txt', 'keeping.insanit', 'cum', 'lionwar.txt', 'ccm.txt', 'bagelman.txt', 'burintrv.78', 'brain.damage', 'paul_har.sto', 'textfile.primer', 'imonly17.txt', 'nigel.7', 'non4', 'toilet.s', 'poem-4.txt', 'lmermaid.txt', 'sre_feqh.txt', 'bulhuntr.txt', 'rid.txt', 'freeman.fil', 'rocket.sf', 'monksol.txt', 'jackmac.fic', 'pussboot.txt', 'enc', 'mtinder.txt', 'quarter.c13', 'fish.txt', 'mouslion.txt', 'bigred.hum', 'quickfix', 'alad10.txt', 'hareleph.txt', 'tearglas.txt', 'lionbird', 'fable.txt', 'thewave', 'poplstrm.txt', 'goldfish.txt', 'arcadia.sty', 'fic3', 'advtthum.txt', 'quarter.c5', 'buggy.txt', 'bookem3', 'srex.txt', 'quarter.c17', 'how.ernie.bert', 'jim.asc', 'fic7', '7voysinb.txt', 'wrt', '3lpigs.txt', 'kharian.txt', 'kneeslapper', 'snowmaid.txt', 'holmesbk.txt', 'tao3.dos', 'blak', 'omarsheh.txt', 'psyc', 'quarter.c4', 'timetrav.txt', 'quarter.c10', 'aminegg.txt', 'quarter.c3', 'burintrv.92', 'space.txt', 'gay', '4moons.txt', 'sretrade.txt', 'wolflamb.txt', 'nigel.4', 'quot', 'empnclot.txt', 'buldetal.txt', 'adler.txt', 'mazarin.txt', 'quarter.c12', 'terrorbears.txt', 'fea1', '18.lws', 'aircon.txt', 'cmoutmou.txt', 'bgb.txt', 'dskool.txt', 'aisle.six', 'girlclub.txt', 'bagel.man', 'startrek.txt', 'excerpt.hum', 'pregn.txt', 'excerpt.txt', 'fantas.hum', 'foxngrap.txt', 'elite.app', 'fear.hum', 'stsgreek', 'bulprint.txt', 'traitor.txt', 'quarter.c15', 'burintrv.66', 'bern', 'vainsong.txt', 'redragon.txt', 'qcarroll', 'stairdre.txt', 'jaynejob.asc', 'quarter.c9', 'arctic.txt', 'bluebrd.txt', 'bulironb.txt', 'aislesix.txt', 'tcoa.txt', 'deathmrs.d', 'weaver.txt', 'emperor3.txt', 'poem-2.txt', '17.lws', 'clevdonk.txt', 'monkking.txt', 'discocanbefun.txt', 'telefone.txt', 'withdraw.cyb', 'floobs.txt', 'gloves.txt', 'tuc_mees', 'game.txt', 'kzap.txt', 'girl', 'mydream.txt', 'curious.george', 'keepmodu.txt', 'flytrunk.txt', 'sre10.txt', 'fic1', 'hotline3.txt', 'bumm', 'dan', 'nigel.2', 'quarter.c8', 'psi', 'mindprob.txt', 'ladylust.hum', 'tin', 'lgoldbrd.txt', 'cardcnt.txt', 'quarter.c14', 'the-tree.txt', 'igiv', 'bulolli2.txt', 'wolfcran.txt', 'timem.hac', 'progx', 'bulnoopt.txt', 'tinsoldr.txt', 'campfire.txt', 'vaincrow.txt', 'bookem.1', 'comp', 'spectacl.poe', 'encamp01.txt', 'crabhern.txt', 'bulwer.lytton', 'pepsi.degenerat', 't_zone.jok', 'friend.s', 'bulfelis.txt', 'sanpedr2.txt', 'bulzork1.txt', 'descent.poe', '3wishes.txt', 'bran', 'hansgrtl.txt', 'quest', 'fleas.txt', 'fic2', 'paink-ws.txt', 'pinocch.txt', 'foxncrow.txt', 'sis', 'angelfur.hum', 'flktrp.txt', 'confilct.fun', 'life.txt', 'stainles.ana', 'quarter.c6', 'horswolf.txt', 'quarter.c7', 'blabnove.txt', 'flute.txt', 'lil', 'knuckle.txt', 'wall.art', 'running.txt', '20.lws', 'graymare.txt', 'plescopm.txt', 'fred.txt', 'rainda.txt', 'times.fic', 'batlslau.txt', 'lionmosq.txt', '14.lws', 'quarter.c16', 'cameloto.hum', 'sleprncs.txt', 'tctac.txt', 'wolf7kid.txt', 'adv_alad.txt', 'non3', 'sqzply.txt', 'sre03.txt', 'ab40thv.txt', 'foxnstrk.txt', 'retrib.txt', 'home.fil', 'fea2', 'beyond.hum', 'vampword.txt', 'deal', 'goldbug.poe', 'pphamlin.txt', 'blue', 'write', 'berternie.txt', 'imagin.hum', 'ezoff', 'island.poe', 'wlgirl.txt', 'chik', 'oxfrog.txt', 'snowqn1.txt', 'szechuan', 'piracy.sto', 'testpilo.hum', 'panama.txt', 'parotsha.txt', '3gables.txt', 's&m_that', 'advsayed.txt', 'hareporc.txt', 'jerichms.hum', 'haretort.txt', 'modemhippy.txt', 'obstgoat.txt', 'frum', 'burn', 'shrdfarm.txt', 'asop', 'healer.txt', 'immorti.hum', 'fowl.death', 'sre_sei.txt', 'shulk.txt', 'gatherng.txt', 'dwar', 'dicegame.txt', 'fearmnky', 'fourth.fic', 'sre01.txt', 'bullove.txt', '3sonnets.vrs', 'greedog.txt', 'lpeargrl.txt', 'frogp.txt', 'sre04.txt', 'blabnove.hum', '19.lws', 'beast.asc', 'bookem2', 'hotline4.txt', 'hell4.txt', 'disco.be.fun', 'tailbear.txt', 'sucker.txt', 'superg1', 'uglyduck.txt', '7oldsamr.txt', 'bestwish', 'nigel.10', 'thanksg', 'myeyes', 'blh.txt', 'eyeargon.hum', 'sunday.txt', 'non2', 'quarter.c19', 'narciss.txt', 'domain.poe', 'mike.txt', 'dicksong.txt', '3student.txt', 'antcrick.txt', 'whgdsreg.reg', 'sre_finl.txt', 'pepdegener.txt', 'glimpse1.txt', 'clon']\n",
            "no of comparisions 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9ZDfzBQ0D9j"
      },
      "source": [
        "Lion stood thoughtfully for a moment."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}